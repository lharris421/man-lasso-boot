A New Perspective on Bootstrap Confidence Intervals for LASSO

Chatterjee and Lahiri (2010) showed that even if the lasso itself is root n consistent (i.e. small enough lambda) that the bootstrap is inconsistent. Indeed, in the classical sense, the bootstrap distributions of the lasso estimators are borderline useless, specifically when p is large relative to n. We have become accustomed to confidence intervals that produce consistent coverage at nominal rates regardless of the magnitude of true underlying parameter. However, to expect confidence intervals based on biased estimators to behave accordingly is admittedly naive. This is why more successful efforts have focused on bootstrapping de-biased versions of the lasso in order to facilitate classical forms of inference. In the process of debiasing, however, the connection to the original model is often obscured. In this work, we offer a different perspective. Bootstrapping lasso estimators may not yield correct coverage in the classical sense for each individual coefficient, but we show it does result in approximately correct average coverage with a slight methodological fix employed. Taking this adjusted perspective means that we also retain the connection to the original model fit.

Author name?
Category 2?